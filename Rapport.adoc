= Rapport miniprojet traitement d'image - REY Quentin
:sectnums:

== Introduction
L'objectif de ce projet est de caractériser les agrégats présents sur les photos afin de pouvoir surveiller leur évolution. Pour cela, plusieurs étapes ont été nécessaires :

. Nettoyer les photos pour enlever les problèmes de luminosité non uniforme +
. Séparer les agrégats pour les avoir en blanc sur fond noir +
. Enlever ceux situés sur le bord pour ne pas fausser les résultats
. Calculer leurs périmètres et leurs aires afin de connaître leurs formes +

Les étapes précédentes ainsi que les résultats obtenus sont présentés dans ce rapport.

== Travail réalisé
=== Nettoyage des imperfections du capteur
Afin de d'obtenir des images propres en limitant les problèmes de luminosité et les imperfections du capteur, j'ai commencé par appliquer un filtre sur l'image qui est composée de la somme de toutes les images, divisé par leur nombre. Cela permet d'obtenir le filtre suivant qui fait ressortir les imperfections communes à toutes les images :

Filtre de luminosité

image:Images rapport/luminosityFilter.bmp[width=300]

Pour accélérer le script python, ce filtre est calculé une première fois puis enregistré. Ensuite, le filtre est récupéré comme une image. +
Après l'application du filtre, l'image est éclairée avec `equalize_hist` afin de mieux faire ressortir les contrats et éliminer les valeurs extrêmes.

Le filtre et l'égalisation ont l'effet suivant :

image:Images rapport/Original-Filtered.png[]

=== Enlever le bruit de fond
Comme on peut le voir sur l'image précédente, l'arrière-plan de la photo est encore très bruité. Pour rendre le font plus noire et enlever les pixels solitaires, j'ai appliqué le filtre morphologique `MORPH_OPEN` de `cv2`. Ainsi, les agrégats se séparent bien du fond.

image:Images rapport/Filtered-MorphedOpen.png[]

=== Application d'un flou gaussien
Si nous zoomons sur l'image précédente, nous pouvons voir que les agrégats sont composés de pixels très clairs et de pixels très foncés. Pour éviter que le seuil servant à la binarisation de l'image laisse la moitié des pixels des agrégats en noir, j'applique un léger filtre gaussien pour uniformiser les pixels avec
`ski.filters.gaussian(morphedImage,1)`

=== Binarisation de l'image
L'étape d'après consiste à séparer les agrégats du fond. Or, certains agrégats sont très clairs alors que d'autres sont plutôt sombres. Pour que tous les agrégats soient détectés, j'ai appliqué un seuil local sur une tuile de la taille d'un agrégat moyen avec la commande suivante :
```py
threshold=ski.filters.threshold_local(bluedImage,301)
binaryImage = bluedImage>threshold
```
Cela donne le résultat suivant :

image:Images rapport/Blured-Binary.png[]

=== Nettoyage image binaire
Afin d'enlever les pixels solitaires sur l'image binarisé, j'ai de nouveau appliqué une opération morphologique avec
```
cv2.morphologyEx(binaryImage, cv2.MORPH_OPEN, np.ones((20, 20), np.uint8))
```

Cela donne le résultat suivant :

image:Images rapport/Binary-MorphedBinary.png[]

=== Lissage image binaire
Puisque la détection de contour fonctionne mieux avec des contours continus, j'ai appliqué un filtre médian qui lisse les agrégats. Cela a aussi l'avantage de refermer la plupart des trous à l'intérieur, ce qui évite de compter de faux contours.
Pour ce faire, j’ai utilisé la commande `medianImage = ski.filters.median(morphedBinaryImage,ski.morphology.disk(10))`

image:Images rapport/MorthedBinary-SmoothedBinary.png[]

=== Suppressions des agrégats touchant les bords
Afin d'avoir une valeur juste de la taille des agrégats, il faut enlever ceux qui touchent les bords, car ceux-là sont coupés en deux. Pour cela, il suffit de créer une bordure de deux pixels sur tout le tour et d'enlever tout ce qui touche cette bordure avec le code suivant :
```py
pad = cv2.copyMakeBorder(image, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=255)
h, w = pad.shape
mask = np.zeros([h + 2, w + 2], np.uint8)
 img_floodfill = cv2.floodFill(pad, mask, (0, 0), 0, (5), (0), flags=8)[1]
```
Cela donne le résultat suivant :

image:Images rapport/SmoothedBinary-Edgeless.png[]

=== Calcul de l'aire et du périmètre
Une fois l'image correctement traitée, détecter les contours est facile avec `cv2.findContours`. La valeur du périmètre et de l'aire de chaque agrégat est sauvegardée dans un document texte afin de pouvoir la récupérer pour tracer l'histogramme. La détection de contour donne cela :

image:Images rapport/Edgeless-Final.png[]

=== Comparaison finale
Ainsi, l'ensemble des transformations précédentes permettent de passer de l'image originale à l'image finale

image:Images rapport/Original-Finale.png[]




== A propos des codes

=== Description et utilisation du code
**preprocessing.py :** Ce code nettoie les images, enregistre la version nettoyée dans un dossier et les aires et les périmètres des agrégats sous forme d'un document texte dans un autre.

Il prend en argument sous forme de variable définie au sommet du fichier le dossier où se trouvent les images à traiter, le fichier dans lequel mettre les images traitées et le fichier dans lequel mettre les documents textes.

Par défaut, il est configuré pour traiter toutes les images du fichier d'entrée. Pour le tester, je conseille donc de mettre seulement quelques images dans le fichier d'entrée. Pour que ce code affiche les étapes intermédiaires, il suffit de décommenter le `plt.show()` à la fin de la boucle for.

**drawHistograms.py :** Ce code lit l'ensemble des fichiers contenant les aires et les périmètres et trace les histogrammes avec. Il prend en entrée le fichier contenant les documents texte.

Afin de faciliter et accélérer son utilisation, le code est fourni avec le filtre et le résultat (documents texte) du traitement d'une partie des images.


=== Le temps d'exécution
Le plus grand point négatif de ce code est son temps d'exécution. C’est pourquoi, le nombre d'étapes pourrait paraître trop grand pour un traitement si simple. Cependant, pour un temps d'exécution total de 9 secondes, 7 secondes sont dues au seuil local et une au filtrage par filtre médian. Ces deux étapes sont absolument essentielles pour une bonne segmentation et une bonne détection des contours. L'ensemble des autres étapes ne représentant qu'une seconde d'exécution. Elles valent le coup au vu de l'amélioration de qualité apportée.

== Résultats

Faute d'échelle afin de pouvoir exprimer les résultats en micromètres, les résultats sont exprimés en pixels.

Sur 175 photos, nous obtenons les résultats suivants pour la répartition des aires et des périmètres en pixels.
image:Images rapport/areas-perimeters.png[]

Ces histogrammes permettent de se rendre compte de deux problèmes dans le traitement des images.

D'une part, il y a un pic pour une aire et un périmètre quasiment nul. Ces valeurs très faibles sont majoritairement liées aux trous dans les agrégats qui n’ont pas étés rebouchés par le filtre médian et qui sont donc comptés comme des agrégats. Pour aller plus loin, on pourrait essayer de boucher ces trous avec une opération morphologique de fermeture sur ces derniers.

De plus, ces graphiques font ressortir le fait qu'il existe de très grandes valeurs d'aire et de périmètre. Ces valeurs sont liées aux agrégats qui sont fusionnés après la binarisation, ce qui donne des agrégats géants. Pour régler ce problème, on pourrait les séparer avec un algorithme de Watershed sur l'image binaire.

Afin de compenser l'étirement des histogrammes liés aux grandes valeurs, voici une version zoomé de ces résultats :

image:Images rapport/zoomed-areas-perimeters.png[]


Ces graphes nous permettent donc de montrer que, pour le set d'images qu'on nous a données, l'aire des agrégats décroît de façon presque exponentielle alors que le périmètre possède un pic aux alentours de 400 pixels. Ces valeurs permettent ainsi de surveiller la composition des agrégats.


== Conclusion
Ce travail a permis de détecter automatiquement les aires et les périmètres des agrégats afin de simplifier leur surveillance. Certaines pistes d'amélioration sont mentionnées précédemment. La principale reste d'améliorer l'efficacité en temps de cet algorithme afin qu'il puisse être utilisé sur un grand nombre de photos très régulièrement.